\documentclass{ULBreport}

\sceau{Pictures/sceauULB.jpg} %To change depending if ULB(sceauULB.jpg) or VUB course (zegelVUB.jpg)

\addbibresource{biblio.bib}

\begin{document}

\titleULB{
	title={Title},
	course={Course unit},
	author={\textit{Author(s) :} \\ Name \\ Name \\ Name},
	date={2023},
	teacher={\textit{Teacher(s) :} \\ Name} \\ Name,
	logo={Pictures/logos.jpg},
        manyAuthor
}


%Bibliography
\nocite{*}
\printbibliography[type=article,title=Articles]

% === 1. INTRODUCTION ===
\section*{Introduction}
Modern cyber threats increasingly rely on stealth and evasion techniques to bypass security measures. Attackers aim to operate undetected within compromised systems for extended periods, executing malicious commands, exfiltrating data, or establishing persistent access. This project focuses on evaluating the effectiveness of built-in Windows security mechanisms, specifically Windows Defender, and potentially other third-party Endpoint Detection and Response (EDR) solutions, against several advanced evasion techniques.

The primary goal is to assess how well these security solutions detect and log activities associated with:
\begin{itemize}
	\item Non-visual or hidden command execution (e.g., leveraging Living Off The Land Binaries and Scripts - LOLBAS).
	\item Keylogger deployment and operation.
	\item Backdoor creation for remote access and persistence.
	\item Process injection and memory manipulation techniques.
	\item Various persistence mechanisms used to maintain access across reboots.
\end{itemize}

By simulating these attacks in a controlled environment and meticulously monitoring system responses through event logs, network traffic analysis, and security alerts, we aim to provide insights into the detection strengths and weaknesses of the evaluated security tools. This report outlines the background concepts, the experimental methodology employed, the results observed, and a discussion of their significance.

% === 2. BACKGROUND ===
\section*{Background}
Understanding the landscape of Windows security and attacker methodologies is crucial for evaluating detection capabilities. This section covers relevant concepts and technologies.

\subsection{Windows Security Architecture}
\textit{[Placeholder: Briefly describe relevant parts of the Windows security model, e.g., User Account Control (UAC), Windows Defender components (Antivirus, Firewall, ATP/Endpoint features if applicable), Event Logging subsystem, permissions model.]}

\subsection{Endpoint Detection and Response (EDR)}
\textit{[Placeholder: Explain what EDR solutions are, how they generally work (beyond traditional antivirus), and their role in detecting advanced threats. Mention Windows Defender's EDR capabilities (Microsoft Defender for Endpoint) if relevant to your tests.]}

\subsection{Common Evasion Techniques}
This project investigates several categories of evasion techniques:
\begin{itemize}
	\item \textbf{Hidden Command Execution (LOLBAS):} Attackers use legitimate, pre-installed Windows tools (LOLBAS) for malicious purposes, often bypassing application whitelisting and reducing the chances of detection. Examples include \texttt{powershell.exe}, \texttt{wmic.exe}, \texttt{certutil.exe}, etc. \cite{lolbas}.
	\item \textbf{Keyloggers:} Software or hardware that records keystrokes, often used to steal credentials or sensitive information \cite{malwarebytes_keyloggers}. Detection can be challenging if they operate stealthily.
	\item \textbf{Backdoors and Persistence:} Techniques used to maintain access to a compromised system after initial entry. This can involve creating hidden user accounts, modifying registry keys, scheduling tasks, or installing rootkits \cite{offensive_security_backdoors, mitre_t1053}.
	\item \textbf{Process Injection:} Methods like DLL injection or process hollowing involve running malicious code within the context of a legitimate process to evade detection \cite{mandiant_hollowing, redteam_dll}.
\end{itemize}

\subsection{Monitoring and Logging}
Effective detection relies on comprehensive monitoring. Key tools and data sources include:
\begin{itemize}
	\item \textbf{Windows Event Logs:} Provide detailed records of system, security, and application events. Specific event IDs are crucial for detecting suspicious activity.
	\item \textbf{Sysinternals Suite:} Tools like Process Monitor (ProcMon) and Sysmon offer deep insights into process creation, network connections, registry modifications, etc. \cite{sysinternals}. Sysmon, in particular, can be configured for enhanced threat detection logging.
	\item \textbf{Network Traffic Analysis:} Tools like Wireshark can capture and analyze network packets to detect command-and-control (C2) communication or data exfiltration.
	* \textbf{Security Solution Logs:} Logs generated by Windows Defender \cite{defender_endpoint} or other EDRs \cite{elastic_security} provide alerts and context.
\end{itemize}

% === 3. DESCRIPTION (Methodology & Setup) ===
\section*{Description: Methodology and Experimental Setup}
This section details the environment, tools, and procedures used to conduct the evaluation.

\subsection{Experimental Environment}
\textit{[Placeholder: Describe the testbed. E.g., Virtual machines (specify software like VirtualBox, VMware), Windows version(s) (e.g., Windows 10 Pro Build XXXX, Windows 11), network configuration (e.g., isolated virtual network, host-only), hardware specifications if relevant.]}

\subsection{Security Solutions Configuration}
\begin{itemize}
	\item \textbf{Windows Defender:} \textit{[Placeholder: Specify how Windows Defender was configured. E.g., Default settings, real-time protection enabled, cloud-delivered protection enabled/disabled, specific exclusions added/removed, Controlled Folder Access status, Attack Surface Reduction rules enabled? Mention if using Defender Antivirus standalone or Microsoft Defender for Endpoint features.]}
	\item \textbf{Third-Party Solutions (If applicable):} \textit{[Placeholder: If other AV/EDR solutions were tested, name them and describe their configuration similarly.]}
\end{itemize}

\subsection{Attack Simulation Procedures}
For each technique, we performed the following steps: \textit{[Placeholder: Provide specific details for each technique. Be precise about the tools and commands used.]}
\begin{itemize}
	\item \textbf{Keylogger Deployment:} \textit{[Placeholder: E.g., Used specific keylogger software (name it), deployment method (e.g., PowerShell script, manual execution), configuration.]}
	\item \textbf{Backdoor Creation:} \textit{[Placeholder: E.g., Used Metasploit Framework \cite{metasploit_docs} to generate a reverse shell payload (specify type), delivery method, established C2 connection.]}
	\item \textbf{Non-Visual Command Execution:} \textit{[Placeholder: E.g., Used specific PowerShell commands (provide examples like Invoke-Expression, Base64 encoded commands \cite{powershell_docs}), WMI commands (\texttt{wmic process call create}), or other LOLBAS techniques (specify which ones from \cite{lolbas}).]}
	\item \textbf{Process Injection:} \textit{[Placeholder: E.g., Used a specific tool/script for DLL injection (name it), target process, or described manual steps for process hollowing.]}
	\item \textbf{Persistence Techniques:} \textit{[Placeholder: E.g., Created a scheduled task using \texttt{schtasks.exe}, added registry run keys (specify path), used WMI event subscriptions.]}
\end{itemize}

\subsection{Monitoring and Data Collection}
During each attack simulation, the following were monitored and logged:
\begin{itemize}
	\item \textbf{Security Alerts:} Alerts generated by Windows Defender / other EDRs were recorded (screenshots, log entries).
	\item \textbf{Windows Event Logs:} Relevant logs (Security, System, Application, PowerShell, Sysmon) were collected and filtered for events related to the attack actions. \textit{[Placeholder: Mention specific Event IDs monitored, e.g., 4688 for process creation, Sysmon Event ID 1, 3, 7, etc.]}
	\item \textbf{Network Traffic:} Network activity was captured using \textit{[Placeholder: e.g., Wireshark]} on \textit{[Placeholder: e.g., the target VM's network interface]} to observe C2 communication or unexpected connections.
	\item \textbf{System Behavior:} Tools like Process Monitor were used to observe file system, registry, and process activity during the attack execution. \textit{[Placeholder: Describe specific filters or observations made.]}
\end{itemize}

\subsection{Evaluation Metrics}
The effectiveness of security solutions was evaluated based on:
\begin{itemize}
	\item \textbf{Detection Rate:} Was the malicious activity detected? (Yes/No/Partial)
	\item \textbf{Alert Quality:} How specific and informative was the alert generated? (e.g., Generic malware vs. specific technique identified)
	\item \textbf{Time to Detection:} How quickly was the activity detected after execution? \textit{[Placeholder: If measurable]}
	\item \textbf{Logging Detail:} Was sufficient information logged in Event Logs or security logs to allow manual investigation and understanding of the attack, even if not automatically alerted?
	\item \textbf{Evasion Success:} Was the technique successful in achieving its immediate goal (e.g., command execution, C2 connection) despite security measures?
\end{itemize}

% === 4. EXPERIMENTAL RESULTS ===
\section*{Experimental Results}
This section presents the findings from the attack simulations against the configured security solutions. Results are organized by the evasion technique tested.

\subsection{Keylogger Deployment}
\textit{[Placeholder: Describe the outcome. E.g., Windows Defender detected the keylogger executable upon download/execution (provide alert details/screenshot). Or, the keylogger ran undetected initially, but specific API calls were logged by Sysmon. Provide data/logs.]}
% Example: \includegraphics[width=0.8\textwidth]{figures/keylogger_alert.png}

\subsection{Backdoor Creation and Remote Access}
\textit{[Placeholder: Describe the outcome. E.g., The Metasploit payload was flagged by Defender AV signature 'XYZ'. Or, the payload executed, established a C2 connection over port 4444, which was visible in network logs but not alerted by Defender. Provide data/logs/screenshots.]}

\subsection{Non-Visual Command Execution}
\textit{[Placeholder: Detail results for different hidden command methods. E.g., Basic PowerShell Invoke-Expression was detected by AMSI/Script Block Logging. Base64 encoded commands bypassed initial detection but were logged. WMIC process creation was logged by Event ID 4688 and Sysmon ID 1, but not flagged as malicious by default. Provide specific commands tested and the corresponding detection/logging results.]}

\subsection{Process Injection}
\textit{[Placeholder: Describe the outcome. E.g., DLL injection into explorer.exe was blocked by Defender's Attack Surface Reduction rule 'XYZ'. Or, Process hollowing using Tool 'ABC' successfully evaded detection, but Sysmon logs showed suspicious cross-process events (Event ID 8, 10). Provide data.]}

\subsection{Persistence Techniques}
\textit{[Placeholder: Detail results for persistence methods. E.g., Adding a registry run key was logged by Sysmon (Event ID 13) but not alerted. Creating a scheduled task via schtasks.exe was logged (Event ID 4688, 4698) but not alerted. WMI persistence triggered specific Defender alerts. Provide data.]}

\subsection{Summary of Findings}
\textit{[Placeholder: Consider adding a summary table comparing detection rates across techniques and solutions.]}
% Example Table:
% \begin{table}[h!]
	% \centering
	% \begin{tabular}{|l|c|c|}
		% \hline
		% \textbf{Technique} & \textbf{Windows Defender Detection} & \textbf{Logging Quality} \\ \hline
		% Keylogger & Detected (Signature) & High \\
		% Backdoor (Metasploit) & Detected (Signature) & High \\
		% PowerShell (Encoded) & Not Alerted & Medium (Script Block Log) \\
		% WMIC Process Create & Not Alerted & Medium (Event ID 4688) \\
		% DLL Injection & Blocked (ASR Rule) & High \\
		% Registry Persistence & Not Alerted & Medium (Sysmon ID 13) \\ \hline
		% \end{tabular}
	% \caption{Summary of Detection Results for Windows Defender.}
	% \label{tab:summary}
	% \end{table}

% === 5. DISCUSSION AND CONCLUSION ===
\section*{Discussion and Conclusion}

\subsection{Discussion}
The experimental results highlight several key aspects of Windows security against evasion techniques. \textit{[Placeholder: Analyze the results presented in the previous section. Why were some techniques detected and others not? Discuss the role of specific features like AMSI, ASR rules, signature-based vs. behavioral detection. Compare Defender's performance against expectations or against other tools if tested. Discuss the importance of non-alert logging (Sysmon, Event Logs) for threat hunting. Were there any surprising results? What are the limitations of this study (e.g., specific tool versions, limited scope)?]}

For instance, techniques relying on known malicious signatures or direct execution of malware (like some keyloggers or basic Meterpreter payloads) were often detected effectively by Windows Defender's standard configuration. However, techniques leveraging LOLBAS, encoded commands, or certain persistence methods often bypassed real-time alerts, emphasizing the need for robust logging and proactive threat hunting. \textit{[Placeholder: Expand this analysis based on your actual findings.]}

The configuration of logging, particularly enabling detailed PowerShell Script Block Logging and deploying Sysmon with a tailored configuration, proved crucial for detecting activities that did not trigger immediate alerts. \textit{[Placeholder: Discuss the trade-offs, e.g., log volume vs. visibility.]}

\subsection{Conclusion}
This project evaluated the detection capabilities of \textit{[Placeholder: Windows Defender and any other tested solutions]} against common security evasion techniques. Our findings indicate that while standard configurations provide a baseline level of protection, particularly against known malware, more sophisticated attacks leveraging legitimate tools (LOLBAS), fileless techniques, and stealthy persistence often require enhanced monitoring and logging capabilities for effective detection.

Key takeaways include: \textit{[Placeholder: Summarize 2-4 main points. E.g., The effectiveness of specific Defender features like ASR. The critical role of Sysmon and detailed logging. The challenge posed by LOLBAS techniques. Recommendations for security hardening based on findings.]}

Future work could involve testing a broader range of evasion techniques, evaluating more third-party EDR solutions, or assessing the impact of different system hardening configurations on detection rates.

% === 6. REFERENCES ===
\section*{References}
% Use a consistent citation style. The simple 'thebibliography' environment is used here.
% For a real report, consider using BibTeX for better management.
\begin{thebibliography}{99}
	
	\bibitem{lolbas} LOLBAS Project. (n.d.). Living Off The Land Binaries, Scripts and Libraries. Retrieved \today, from \url{https://lolbas-project.github.io/}
	
	\bibitem{powershell_docs} Microsoft Learn. (n.d.). PowerShell Documentation. Retrieved \today, from \url{https://learn.microsoft.com/en-us/powershell/}
	
	\bibitem{malwarebytes_keyloggers} Malwarebytes Labs. (n.d.). What are keyloggers? Retrieved \today, from \url{https://www.malwarebytes.com/keyloggers} % (Adjust title if needed based on actual page)
	
	\bibitem{microsoft_security_blog} Microsoft Security Blog. (n.d.). Retrieved \today, from \url{https://www.microsoft.com/security/blog}
	
	\bibitem{offensive_security_backdoors} Offensive Security. (n.d.). Persistent Backdoors. Metasploit Unleashed. Retrieved \today, from \url{https://www.offensive-security.com/metasploit-unleashed/persistent-backdoors}
	
	\bibitem{metasploit_docs} Rapid7. (n.d.). Metasploit Documentation. Retrieved \today, from \url{https://docs.rapid7.com/metasploit}
	
	\bibitem{mandiant_hollowing} Mandiant. (n.d.). Process Hollowing. Mandiant Resources. Retrieved \today, from \url{https://www.mandiant.com/resources/process-hollowing} % (Adjust title/URL if needed)
	
	\bibitem{redteam_dll} Red Team Journal. (n.d.). DLL Injection. Retrieved \today, from \url{https://www.redteamjournal.com/dll-injection} % (Adjust title/URL if needed)
	
	\bibitem{mitre_t1053} MITRE ATT\&CK. (n.d.). Technique T1053: Scheduled Task/Job. Retrieved \today, from \url{https://attack.mitre.org/techniques/T1053/} % (Note: Proposal linked T1053, which is Scheduled Task. Adjust if other persistence was primary focus)
	
	\bibitem{sysinternals} Microsoft Learn. (n.d.). Sysinternals Utilities. Retrieved \today, from \url{https://docs.microsoft.com/en-us/sysinternals/}
	
	\bibitem{defender_endpoint} Microsoft Learn. (n.d.). Microsoft Defender for Endpoint Documentation. Retrieved \today, from \url{https://learn.microsoft.com/en-us/microsoft-365/security/defender-endpoint/}
	
	\bibitem{elastic_security} Elastic. (n.d.). Elastic Security Solution. Retrieved \today, from \url{https://www.elastic.co/security}
	
	% === ADD ANY OTHER REFERENCES USED ===
	\bibitem{placeholder_ref} [Placeholder: Author(s)]. ([Placeholder: Year]). \textit{[Placeholder: Title of work]}. [Placeholder: Publication details or URL].
	
\end{thebibliography}

% === DOCUMENT END ===

\end{document}
